{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_data_test.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishna040705/ZeroOneCodeClub_FirstWebDevProject/blob/main/notebooks/traffic_counter_yolov5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fNDvNWOWvpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a87d7a-93bb-4706-93c3-639063ccab2d"
      },
      "source": [
        "!pip install pafy\n",
        "!pip install -q youtube-dl\n",
        "\n",
        "!pip install yolov5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pafy\n",
            "  Downloading pafy-0.5.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Downloading pafy-0.5.5-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: pafy\n",
            "Successfully installed pafy-0.5.5\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yolov5\n",
            "  Downloading yolov5-7.0.14-py37.py38.py39.py310-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from yolov5) (3.1.44)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from yolov5) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from yolov5) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from yolov5) (11.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from yolov5) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from yolov5) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (1.14.1)\n",
            "Collecting thop>=0.1.1 (from yolov5)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from yolov5) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from yolov5) (4.67.1)\n",
            "Collecting ultralytics>=8.0.100 (from yolov5)\n",
            "  Downloading ultralytics-8.3.107-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (2.18.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from yolov5) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from yolov5) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.11/dist-packages (from yolov5) (75.2.0)\n",
            "Collecting fire (from yolov5)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3>=1.19.1 (from yolov5)\n",
            "  Downloading boto3-1.37.32-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting sahi>=0.11.10 (from yolov5)\n",
            "  Downloading sahi-0.11.22-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting huggingface-hub<0.25.0,>=0.12.0 (from yolov5)\n",
            "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting roboflow>=0.2.29 (from yolov5)\n",
            "  Downloading roboflow-1.1.60-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting botocore<1.38.0,>=1.37.32 (from boto3>=1.19.1->yolov5)\n",
            "  Downloading botocore-1.37.32-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.19.1->yolov5)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3>=1.19.1->yolov5)\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->yolov5) (4.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (4.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->yolov5) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->yolov5) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5) (2025.1.31)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.23.0->yolov5)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow>=0.2.29->yolov5)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow>=0.2.29->yolov5)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting python-dotenv (from roboflow>=0.2.29->yolov5)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.29->yolov5) (1.17.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.29->yolov5) (1.0.0)\n",
            "Collecting filetype (from roboflow>=0.2.29->yolov5)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sahi>=0.11.10->yolov5) (8.1.8)\n",
            "Collecting opencv-python>=4.1.1 (from yolov5)\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pybboxes==0.1.6 (from sahi>=0.11.10->yolov5)\n",
            "  Downloading pybboxes-0.1.6-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from sahi>=0.11.10->yolov5) (2.1.0)\n",
            "Collecting terminaltables (from sahi>=0.11.10->yolov5)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (5.29.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5) (3.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.7.0->yolov5)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.7.0->yolov5)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.7.0->yolov5)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7.0->yolov5)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7.0->yolov5)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7.0->yolov5)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7.0->yolov5)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7.0->yolov5)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7.0->yolov5)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7.0->yolov5)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->yolov5) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.0.100->yolov5) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.0.100->yolov5)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->yolov5) (3.0.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->yolov5) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->yolov5) (3.0.2)\n",
            "Downloading yolov5-7.0.14-py37.py38.py39.py310-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.5/953.5 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.37.32-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roboflow-1.1.60-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sahi-0.11.22-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybboxes-0.1.6-py3-none-any.whl (24 kB)\n",
            "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.107-py3-none-any.whl (974 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.5/974.5 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.32-py3-none-any.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=eebce21325257662b6dc86a21e96f6fea9d61385d66c7027850546e6f7b35aa2\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: filetype, terminaltables, python-dotenv, pybboxes, pillow-heif, opencv-python-headless, opencv-python, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, idna, fire, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, sahi, s3transfer, nvidia-cusolver-cu12, huggingface-hub, roboflow, boto3, ultralytics-thop, thop, ultralytics, yolov5\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.30.1\n",
            "    Uninstalling huggingface-hub-0.30.1:\n",
            "      Successfully uninstalled huggingface-hub-0.30.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.50.3 requires huggingface-hub<1.0,>=0.26.0, but you have huggingface-hub 0.24.7 which is incompatible.\n",
            "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.24.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed boto3-1.37.32 botocore-1.37.32 filetype-1.2.0 fire-0.7.0 huggingface-hub-0.24.7 idna-3.7 jmespath-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opencv-python-4.10.0.84 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 pybboxes-0.1.6 python-dotenv-1.1.0 roboflow-1.1.60 s3transfer-0.11.4 sahi-0.11.22 terminaltables-3.1.10 thop-0.1.1.post2209072238 ultralytics-8.3.107 ultralytics-thop-2.0.14 yolov5-7.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O1sEH6MGFlR"
      },
      "source": [
        "git clone DLTrafficCounter and yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzHMg6kNuJay"
      },
      "source": [
        "!git clone https://github.com/changsin/DLTrafficCounter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sp8S964yARl"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccpQvXLlatKP"
      },
      "source": [
        "Download pretrained yolov5 model\n",
        "Choose one of the pretrained models from https://github.com/ultralytics/yolov5#inference\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5pTcJ1fyG5T"
      },
      "source": [
        "!wget https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOm6wEw-rxG-"
      },
      "source": [
        "%cd yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q78FdC1uLk9"
      },
      "source": [
        "!python train.py --img 640 --batch 10  --epochs 400 --data ../DLTrafficCounter/configs/train_traffic_counter.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6TZYhgNB9bH"
      },
      "source": [
        "\n",
        "\n",
        "### 400 epochs with 90:10:0 split\n",
        "\n",
        "```\n",
        "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
        "   399/399      2.3G   0.03166   0.08281  0.004935       513       640: 100% 9/9 [00:00<00:00, 11.46it/s]\n",
        "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:01<00:00,  2.80it/s]\n",
        "                 all         90       2332      0.948      0.737      0.811      0.658\n",
        "                 car         90       1633      0.968      0.927      0.977      0.775\n",
        "                 bus         90         45      0.933      0.378      0.483      0.422\n",
        "               truck         90        654      0.944      0.907      0.974      0.778\n",
        "\n",
        "400 epochs completed in 0.182 hours.\n",
        "Optimizer stripped from runs/train/exp19/weights/last.pt, 14.4MB\n",
        "Optimizer stripped from runs/train/exp19/weights/best.pt, 14.4MB\n",
        "Results saved to runs/train/exp19\n",
        "```\n",
        "\n",
        "### 600 epochs with 80:10:10 split\n",
        "\n",
        "```\n",
        "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
        "   599/599     2.18G   0.02807    0.0649   0.00359       400       640: 100% 8/8 [00:01<00:00,  5.25it/s]\n",
        "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  5.25it/s]\n",
        "                 all         10        344      0.704      0.709      0.759      0.518\n",
        "                 car         10        232      0.751      0.858      0.871      0.613\n",
        "                 bus         10          4      0.666        0.5      0.599      0.399\n",
        "               truck         10        108      0.696      0.769      0.807      0.542\n",
        "```\n",
        "\n",
        "\n",
        "### 500 epoch with 80:10:10 split\n",
        "\n",
        "```\n",
        "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
        "   499/499     2.18G   0.02674   0.06836  0.003731       388       640: 100% 8/8 [00:01<00:00,  5.20it/s]\n",
        "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  5.31it/s]\n",
        "                 all         10        344      0.661      0.713      0.723      0.488\n",
        "                 car         10        232      0.656      0.871      0.867      0.593\n",
        "                 bus         10          4      0.661        0.5      0.499      0.329\n",
        "               truck         10        108      0.665      0.769      0.804      0.542\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERh0KS3UBYe-"
      },
      "source": [
        "car 209\n",
        "bus 12\n",
        "truck 112\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CY-FOgFW5Gr"
      },
      "source": [
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.5 --source ../DLTrafficCounter/data/bbox_highway/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePHBhTXUJbRZ"
      },
      "source": [
        "- Run against the customized and better vehicle detection model.\n",
        "(If you are running yourself, you need to modify the path of the weights file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CML-7VNysJSG"
      },
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.5 --source ../DLTrafficCounter/data/bbox_highway/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeGM4abIWYZ8",
        "outputId": "0c19564f-4f2f-423c-df1e-1748bfa13635"
      },
      "source": [
        "!python detect.py --weights ../DLTrafficCounter/models/yolov5s_highway.pt --img 640 --conf 0.5 --source ../DLTrafficCounter/data/bbox_highway/test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../DLTrafficCounter/models/yolov5s_highway.pt'], source=../DLTrafficCounter/data/bbox_highway/test, imgsz=640, conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 🚀 v5.0-351-ge96c74b torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7059304 parameters, 0 gradients, 16.3 GFLOPs\n",
            "image 1/5 /content/yolov5/yolov5/../DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_096.png: 384x640 12 cars, 5 trucks, Done. (0.009s)\n",
            "image 2/5 /content/yolov5/yolov5/../DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_097.png: 384x640 8 cars, 7 trucks, Done. (0.007s)\n",
            "image 3/5 /content/yolov5/yolov5/../DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_098.png: 384x640 38 cars, 22 trucks, Done. (0.007s)\n",
            "image 4/5 /content/yolov5/yolov5/../DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_099.png: 384x640 47 cars, 3 buss, 17 trucks, Done. (0.007s)\n",
            "image 5/5 /content/yolov5/yolov5/../DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_100.png: 384x640 38 cars, 1 bus, 17 trucks, Done. (0.007s)\n",
            "Results saved to \u001b[1mruns/detect/exp6\u001b[0m\n",
            "Done. (0.785s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL5gKdpA_VCg"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "[tensor([[ 0.73203,  0.43620,  0.85469,  0.88646,  0.90088,  0.00000],\n",
        "         [ 0.70586,  0.36276,  0.92344,  0.49609,  0.62939, 25.00000],\n",
        "         [ 0.58125,  0.40365,  0.73984,  0.78594,  0.46143, 77.00000],\n",
        "         [ 0.39355,  0.15990,  0.58789,  0.80365,  0.44385, 10.00000],\n",
        "         [ 0.19248,  0.50104,  0.20469,  0.54062,  0.29517,  0.00000]], device='cuda:0')]\n",
        "```\n",
        "results.xyxy and results.pred have the same content except in scientific notations.\n",
        "```\n",
        "[tensor([[1.75687e+03, 7.85156e+02, 2.05125e+03, 1.59562e+03, 9.00879e-01, 0.00000e+00],\n",
        "         [1.69406e+03, 6.52969e+02, 2.21625e+03, 8.92969e+02, 6.29395e-01, 2.50000e+01],\n",
        "         [1.39500e+03, 7.26562e+02, 1.77562e+03, 1.41469e+03, 4.61426e-01, 7.70000e+01],\n",
        "         [9.44531e+02, 2.87812e+02, 1.41094e+03, 1.44656e+03, 4.43848e-01, 1.00000e+01],\n",
        "         [4.61953e+02, 9.01875e+02, 4.91250e+02, 9.73125e+02, 2.95166e-01, 0.00000e+00]], device='cuda:0')]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t5lmfBT_6jl"
      },
      "source": [
        "With this information, we can now parse and count each vehicle type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8xTskHP5jAy"
      },
      "source": [
        "## Plot annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJnZzGK2bh6F"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "def glob_files(path, file_type=\"*\"):\n",
        "    search_string = os.path.join(path, file_type)\n",
        "    files = glob.glob(search_string)\n",
        "\n",
        "    # print('searching ', path)\n",
        "    paths = []\n",
        "    for f in files:\n",
        "      if os.path.isdir(f):\n",
        "        sub_paths = glob_files(f + '/')\n",
        "        paths += sub_paths\n",
        "      else:\n",
        "        paths.append(f)\n",
        "\n",
        "    # We sort the images in alphabetical order to match them\n",
        "    #  to the annotation files\n",
        "    paths.sort()\n",
        "\n",
        "    return paths\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ_C0gh4TdbZ"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "IMAGE_SIZE = 600\n",
        "\n",
        "def load_images(path):\n",
        "  files = glob_files(path, \"*.png\")\n",
        "\n",
        "  # print(files)\n",
        "  X_data = []\n",
        "  for file in files:\n",
        "    image = cv2.imread(file)\n",
        "    # print(image.shape)\n",
        "    # x = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    X_data.append(image)\n",
        "  return np.array(X_data)\n",
        "\n",
        "X_test = load_images(\"/content/DLTrafficCounter/data/bbox_highway/test/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im3rf-9oUBCI"
      },
      "source": [
        "WIDTH = 1920\n",
        "HEIGHT = 1080\n",
        "\n",
        "def load_labels(path):\n",
        "  files = glob_files(path, \"*.txt\")\n",
        "\n",
        "  Y_data = []\n",
        "  for file in files:\n",
        "    with open(file) as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "      boxes = []\n",
        "      for line in lines:\n",
        "        tokens = line.split()\n",
        "\n",
        "        class_id = int(tokens[0])\n",
        "        xc = float(tokens[1]) * WIDTH\n",
        "        yc = float(tokens[2]) * HEIGHT\n",
        "        width = float(tokens[3]) * WIDTH\n",
        "        height = float(tokens[4]) * HEIGHT\n",
        "\n",
        "        boxes.append(np.array([class_id, xc, yc, width, height]))\n",
        "        # print(class_id, xc, yc, width, height)\n",
        "\n",
        "      Y_data.append(np.array(boxes))\n",
        "      # print(lines)\n",
        "  return np.array(Y_data)\n",
        "\n",
        "Y_test = load_labels(\"/content/DLTrafficCounter/data/bbox_highway/test/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "OLVDsqz2WYHh",
        "outputId": "045f2b70-470a-478d-ef49-05df721fc236"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def create_patch_rectangle(y, color):\n",
        "  # # in yolov5\n",
        "  width = int(y[2])\n",
        "  height = int(y[3])\n",
        "  return patches.Rectangle((int(y[0] - width/2), int(y[1] - height/2)),\n",
        "                           width, height,\n",
        "                           edgecolor=color, fill=False)\n",
        "\n",
        "COLORS = [(0, 255/255, 0), (255/255, 255/255, 0), (255/255, 0, 0)]\n",
        "\n",
        "def plot_image(image, boxes, axis):\n",
        "  # # print(boxes.shape)\n",
        "  for box in boxes:\n",
        "    # print(box)\n",
        "    class_id = int(box[0])\n",
        "    # print(type(class_id), class_id)\n",
        "    rect = create_patch_rectangle(box[1:], COLORS[class_id])\n",
        "    axis.add_patch(rect)\n",
        "\n",
        "  plt.imshow(image)\n",
        "\n",
        "def plot_images(X, Y, limit=10):\n",
        "  fig = plt.figure(figsize=(100, 80))\n",
        "\n",
        "  last_id = min(limit, X.shape[0])\n",
        "  for id in range(last_id):\n",
        "    axis = fig.add_subplot(5, 3, id + 1)\n",
        "    axis.get_xaxis().set_visible(False)\n",
        "    axis.get_yaxis().set_visible(False)\n",
        "    plot_image(X[id], Y[id], axis)\n",
        "\n",
        "plot_images(np.array([X_test[-1]]), np.array([Y_test[-1]]))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ede8335802d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mplot_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSayIVTsJJh2"
      },
      "source": [
        "Y_test[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfoGM3Tpl3vc"
      },
      "source": [
        "def dict_increment(dict1, key):\n",
        "  if key in dict1.keys():\n",
        "    dict1[key] = dict1[key] + 1\n",
        "  else:\n",
        "    dict1[key] = 1\n",
        "\n",
        "  return dict1\n",
        "\n",
        "def add_dicts(dict1, dict2):\n",
        "  dict3 = dict()\n",
        "\n",
        "  for key1, val1 in dict1.items():\n",
        "    dict3[key1] = val1\n",
        "    if key1 in dict2.keys():\n",
        "      dict3[key1] = val1 + dict2[key1]\n",
        "\n",
        "  for key2, val2 in dict2.items():\n",
        "    if key2 not in dict1.keys():\n",
        "      dict3[key2] = val2\n",
        "\n",
        "  return dict3\n",
        "\n",
        "dict1 = {}\n",
        "\n",
        "dict1 = dict_increment(dict1, 'car')\n",
        "dict1 = dict_increment(dict1, 'car')\n",
        "dict1 = dict_increment(dict1, 'bus')\n",
        "dict1\n",
        "\n",
        "dict2 = {}\n",
        "dict2 = dict_increment(dict2, 'car')\n",
        "dict2 = dict_increment(dict2, 'bus')\n",
        "dict2 = dict_increment(dict2, 'truck')\n",
        "dict2 = dict_increment(dict2, 'truck')\n",
        "dict2\n",
        "\n",
        "dict3 = add_dicts(dict1, dict2)\n",
        "add_dicts(dict3, dict2)\n",
        "add_dicts(dict1, dict2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrq0sGgoVrzs"
      },
      "source": [
        "def print_class_counts(dict1, class_names):\n",
        "  # print counts for each class name\n",
        "  for key, val in dict1.items():\n",
        "    print(class_names[key], val)\n",
        "\n",
        "def count_vehicles(detection_res, confidence_threshold=0.5):\n",
        "  counts = dict()\n",
        "  # print(res.names.index('car'), res.names.index('bus'), res.names.index('truck'))\n",
        "\n",
        "  for pred in detection_res.xyxyn[0]:\n",
        "    confidence = pred[-2]\n",
        "    if confidence > confidence_threshold:\n",
        "      # print(pred)\n",
        "\n",
        "      class_id = int(pred[-1])\n",
        "      counts = dict_increment(counts, class_id)\n",
        "\n",
        "  print_class_counts(counts, detection_res.names)\n",
        "  return counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBYlW6rjXytC"
      },
      "source": [
        "def count_vehicles_total(model, path, file_type=\"*.png\", confidence_threshold=0.5):\n",
        "  filenames = glob_files(path, file_type=file_type)\n",
        "  total_counts = dict()\n",
        "  class_names = None\n",
        "\n",
        "  for filename in filenames:\n",
        "    detection_res = model(filename)\n",
        "    if not class_names:\n",
        "      class_names = detection_res.names\n",
        "\n",
        "    counts = count_vehicles(detection_res,\n",
        "                            confidence_threshold=confidence_threshold)\n",
        "\n",
        "    # print(os.path.basename(filename), counts)\n",
        "    total_counts = add_dicts(total_counts, counts)\n",
        "\n",
        "  # print counts for each class name\n",
        "  print(\"\\nTotal counts:\")\n",
        "  print_class_counts(total_counts, class_names)\n",
        "\n",
        "  return total_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhqiZy53VVaW"
      },
      "source": [
        "CLASSES = ['car', 'bus', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_i0TPCQemTW"
      },
      "source": [
        "import yolov5\n",
        "\n",
        "model_baseline = yolov5.load('yolov5s.pt')\n",
        "count_vehicles_total(model_baseline, '/content/DLTrafficCounter/data/bbox_highway/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPcjkcv9TClt"
      },
      "source": [
        "model_highway = yolov5.load('/content/DLTrafficCounter/models/yolov5s_highway.pt')\n",
        "count_vehicles_total(model_highway, '/content/DLTrafficCounter/data/bbox_highway/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aU9G7oQvwg0"
      },
      "source": [
        "def count_vehicles_in_annotations(Y):\n",
        "  \"\"\"\n",
        "  count vehicles in the annotations\n",
        "  \"\"\"\n",
        "\n",
        "  total_counts = dict()\n",
        "  for y in Y:\n",
        "    counts = dict()\n",
        "    for ann in y:\n",
        "      counts = dict_increment(counts, int(ann[0]))\n",
        "\n",
        "    total_counts = add_dicts(total_counts, counts)\n",
        "    # print(len(y), total_counts)\n",
        "  print_class_counts(total_counts, CLASSES)\n",
        "\n",
        "count_vehicles_in_annotations(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twtGrdjExVPB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3YYfZEKxVp9"
      },
      "source": [
        "| Type  | Ground Truth  | Yolo Pretrained  | Cutom Trained |\n",
        "|---|---|---|---|\n",
        "| bus  | 10  | 4  |  4   |\n",
        "| car  | 147  | 48  |  143   |\n",
        "| truck  | 68  | 9 | 68  |\n",
        "| train  | 0  | 1 | 0  |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is_fRDu3dffy"
      },
      "source": [
        "Y_train = load_labels(\"/content/DLTrafficCounter/data/bbox_highway/train/\")\n",
        "count_vehicles_in_annotations(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8FbJAPxdrTG"
      },
      "source": [
        "Y_val = load_labels(\"/content/DLTrafficCounter/data/bbox_highway/val/\")\n",
        "count_vehicles_in_annotations(Y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW_fk9bYc7YM"
      },
      "source": [
        "# Real-time inferencing\n",
        "With the vehicle counting code, we can actually test against a real stream of traffic data. Here is an example. You will see that it does not work in all cases. More data is needed to make it robust, but now you know how to do it. Enjoy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPvajqlISFOX"
      },
      "source": [
        "import pafy\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Village of Tilton - Traffic Camera\n",
        "# url = \"https://youtu.be/5_XSYlAfJZM\"\n",
        "\n",
        "# url = \"https://youtu.be/TgXWC2o8nzA\"\n",
        "\n",
        "# Gwanghwamun\n",
        "# url = \"https://youtu.be/W8T-qz93QCI\"\n",
        "\n",
        "# 부산 광안대교 실시간 CCTV 교통정보\n",
        "url = \"https://youtu.be/pUcWdJoAuyw\"\n",
        "\n",
        "video = pafy.new(url)\n",
        "best = video.getbest(preftype=\"mp4\")\n",
        "\n",
        "while True:\n",
        "    capture = cv2.VideoCapture(best.url)\n",
        "    grabbed, frame = capture.read()\n",
        "\n",
        "    detected = model_highway(frame)\n",
        "    detected.save(\"results\")\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    count_vehicles(detected)\n",
        "    cv2_imshow(detected.imgs[0])\n",
        "    # print(grabbed, frame.shape)\n",
        "\n",
        "    time.sleep(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukqOv15GBF2s"
      },
      "source": [
        "# Appendix\n",
        "## To convert MS COCO xml to YOLO V5 annotation files\n",
        "Here is the code that I used to convert a single MS COCO xml file to YOLO V5 annotation files, one annotation text file for each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1JVGHcnBRrY"
      },
      "source": [
        "import numpy as np\n",
        "import lxml\n",
        "\n",
        "from lxml import etree\n",
        "\n",
        "CLASSES = [\"car\", \"bus\", \"truck\"]\n",
        "\n",
        "def to_yolov5(y):\n",
        "  \"\"\"\n",
        "  # change to yolo v5 format\n",
        "  # https://github.com/ultralytics/yolov5/issues/12\n",
        "  # [x_top_left, y_top_left, x_bottom_right, y_bottom_right] to\n",
        "  # [x_center, y_center, width, height]\n",
        "  \"\"\"\n",
        "  width = y[2] - y[0]\n",
        "  height = y[3] - y[1]\n",
        "\n",
        "  if width < 0 or height < 0:\n",
        "      print(\"ERROR: negative width or height \", width, height, y)\n",
        "      raise AssertionError(\"Negative width or height\")\n",
        "  return (y[0] + (width/2)), (y[1] + (height/2)), width, height\n",
        "\n",
        "def load_xml_annotations(f):\n",
        "  tree = etree.parse(f)\n",
        "  anns = []\n",
        "  for dim in tree.xpath(\"image\"):\n",
        "    image_filename = dim.attrib[\"name\"]\n",
        "    width = int(dim.attrib[\"width\"])\n",
        "    height = int(dim.attrib[\"height\"])\n",
        "    # print(image_filename)\n",
        "    # print(len(dim.xpath(\"box\")))\n",
        "    boxes = []\n",
        "    for box in dim.xpath(\"box\"):\n",
        "      label = CLASSES.index(box.attrib[\"label\"])\n",
        "      xtl, ytl = box.attrib[\"xtl\"], box.attrib[\"ytl\"]\n",
        "      xbr, ybr = box.attrib[\"xbr\"], box.attrib[\"ybr\"]\n",
        "\n",
        "      xc, yc, w, h = to_yolov5([float(xtl), float(ytl), float(xbr), float(ybr)])\n",
        "      boxes.append([label, round(xc/width, 5), round(yc/height, 5), round(w/width, 5), round(h/height, 5)])\n",
        "\n",
        "    anns.append([image_filename, width, height, boxes])\n",
        "\n",
        "  return np.array(anns)\n",
        "\n",
        "anns = load_xml_annotations(label_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtTNnxDWBo3O"
      },
      "source": [
        "def write_yolov5_txt(folder, annotation):\n",
        "  out_filename = folder + annotation[0][:-3] + 'txt'\n",
        "  f = open(out_filename,\"w+\")\n",
        "  for box in annotation[3]:\n",
        "    f.write(\"{} {} {} {} {}\\n\".format(box[0], box[1], box[2], box[3], box[4]))\n",
        "\n",
        "for ann in anns:\n",
        "  write_yolov5_txt(DATA_ROOT + 'train/', ann)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}